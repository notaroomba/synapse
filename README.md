**### Make a fork or copy of this repo and fill in your team submission details! ###**

# AMD_Robotics_Hackathon_2025_[Project Name]

## Team Information

**Team:** Team Synapse • Team #3 — GitHub: `@notaroomba`, `@kalo08`, `@oxstar123`

**Summary:** Synapse is a teleoperated surgical robot demonstrator that uses machine learning (SMVLA) to assist high-precision tasks and reduce human error in complex medical procedures.

**Demo media:** Local demo video: `assets/demo.mp4`; photos: `assets/photo1.png`, `assets/photo2.png`, `assets/photo3.png`

## Submission Details

### 1. Mission Description
- Demonstrate how machine learning can be used in surgical teleoperation to assist complex surgeries and reduce human error.

### 2. Creativity
- **SCALPEL**: synchronized control arm with low-latency precision engineering links for coordinated, high-accuracy teleoperation.
- Integration of SMVLA-trained policies with real-time teleoperation and an operator override/takeover toggle for assisted autonomy. ALso has a cool cardboard person that simulates an actual surgery.

### 3. Technical implementations
- Teleoperation / Dataset capture
    - WebSocket server (`main.py`) receives head/hand pose and control inputs from a Meta Quest 3 client; dataset capture and teleop logs can be placed in `missions/code/` and `missions/wandb/`.
- Training
    - Model was trained using **SMVLA** and reached an MVP after approximately **50** iterations.
- Inference
    - Operator can enable **SCALPEL** takeover (assist/autonomy) via the Meta Quest interface; runtime started with `./run_robot.sh` and `main.py` handles inference and control.

### 4. Ease of use
- Implementation follows LERobot conventions and is intended to be adaptable to similar teleoperation tasks and environments.
- Flexible and scriptable; supports a Meta Quest 3 teleop client and local runtime scripts.
- Control interfaces: WebSocket-based headset client and local scripts; `./setup.sh` guides hardware/port configuration (see LERobot docs for environment setup).

## Additional Links
*For example, you can provide links to:*

- Local demo video: `assets/demo.mp4`
- URL of your dataset in Hugging Face: https://huggingface.co/datasets/NotARoomba/synapse_5
- URL of your model in Hugging Face: https://huggingface.co/NotARoomba/eval_synapse_smvla_5
- Link to a blog post describing your work:
- Repository: https://github.com/notaroomba/synapse

## Code submission

This is the directory tree of this repo — please place all submission materials into the `missions` directory with the structure below.

```terminal
AMD_Robotics_Hackathon_2025_ProjectTemplate-main/
├── README.md
└── missions
    ├── code
    │   └── <code and script>
    └── wandb
        └── <latest run directory copied from wandb of your training job>
    ├── CAD
    │   └── <CAD files>
    └── calibrations
        └── <calibration files (e.g., leader.json, follower.json)>
```


The `latest-run` is generated by wandb for your training job. Please copy it into the wandb sub directory of you Hackathon Repo.

The whole dir of `latest-run` will look like below:

```terminal
$ tree outputs/train/smolvla_so101_2cube_30k_steps/wandb/
outputs/train/smolvla_so101_2cube_30k_steps/wandb/
├── debug-internal.log -> run-20251029_063411-tz1cpo59/logs/debug-internal.log
├── debug.log -> run-20251029_063411-tz1cpo59/logs/debug.log
├── latest-run -> run-20251029_063411-tz1cpo59
└── run-20251029_063411-tz1cpo59
    ├── files
    │   ├── config.yaml
    │   ├── output.log
    │   ├── requirements.txt
    │   ├── wandb-metadata.json
    │   └── wandb-summary.json
    ├── logs
    │   ├── debug-core.log -> /dataset/.cache/wandb/logs/core-debug-20251029_063411.log
    │   ├── debug-internal.log
    │   └── debug.log
    ├── run-tz1cpo59.wandb
    └── tmp
        └── code
```

**NOTES**

1. The `latest-run` is the soft link, please make sure to copy the real target directory it linked with all sub dirs and files.
2. Only provide (upload) the wandb of your last success pre-trained model for the Mission.
